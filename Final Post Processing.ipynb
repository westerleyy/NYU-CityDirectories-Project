{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules \n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# test file path\n",
    "path = \"./test_directory_files/\"\n",
    "tsv = \"tsv/\"\n",
    "locations = \"4b119360-317a-0134-9131-00505686a51c_locations.tsv\"\n",
    "occupations = \"4b119360-317a-0134-9131-00505686a51c_occupations.tsv\"\n",
    "subjects = \"4b119360-317a-0134-9131-00505686a51c_subjects.tsv\"\n",
    "test_json = \"119.56837603.5abc93e0-6e04-0134-173e-00505686a51c_labeled.json\"\n",
    "street_names_txt = \"./city-directory-entry-parser-master/streetnames.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open tsvs and streetnames\n",
    "## From Nick: Columns are the directory uuid, page uuid, entry uuid, the number (in 0,1,2,3 index order) of the entry \n",
    "##            (remember that there could be more than one subject per entry, more than one occupation, etc.).Most are \n",
    "##            entry 0, but sometimes you might find an entry 1 if there are multiple subjects/occupations/locations. \n",
    "##            Then an offset number, e.g. the order of the token from the start of the entry. So a 0th token, 1st token,\n",
    "##            2nd token, etc. And finally the token itself in the last column.\n",
    "##            Remember that we have to keep that entry and offset number linked to each token otherwise we won't be able \n",
    "##            to swap any corrections back into the JSON file once we have a listed of recommended edits.\n",
    "\n",
    "locations_tsv = pd.read_csv(path + tsv + locations, \n",
    "                           sep = \"\\t\",\n",
    "                           quoting = csv.QUOTE_NONE)\n",
    "occupations_tsv = pd.read_csv(path + tsv + occupations, \n",
    "                           sep = \"\\t\",\n",
    "                           quoting = csv.QUOTE_NONE)\n",
    "subjects_tsv = pd.read_csv(path + tsv + subjects, \n",
    "                           sep = \"\\t\",\n",
    "                           quoting = csv.QUOTE_NONE)\n",
    "master_street_names = pd.read_csv(street_names_txt, \n",
    "                                  header = None)\n",
    "master_street_names = master_street_names[0].tolist()\n",
    "#master_street_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164615\n"
     ]
    }
   ],
   "source": [
    "print(locations_tsv.entry_uuid.nunique())\n",
    "#locations_tsv.head(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function remove punctuation and default to lowercase\n",
    "def clean_token(token):\n",
    "    token_lower = token.lower()\n",
    "    token_clean = ''.join(t for t in token_lower if t.isalnum())\n",
    "    return token_clean\n",
    "\n",
    "# apply to column and create new column\n",
    "locations_tsv[\"token_re\"] = locations_tsv[\"token\"].apply(clean_token)\n",
    "\n",
    "# drop rows with just non alpha-numeric characters\n",
    "locations_tsv = locations_tsv.drop(locations_tsv[(locations_tsv.token_re == '')].index)\n",
    "\n",
    "# create trial pd\n",
    "locations_tsv_trunc = locations_tsv.sample(n = 100)\n",
    "#locations_tsv_trunc.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = timer()\n",
    "\n",
    "def fuzzy_match(x, choices, scorer):\n",
    "    # check if numeric:\n",
    "    digit_check = x.isdigit()\n",
    "    if digit_check is True:\n",
    "        #print(\"numeric\")\n",
    "        return x\n",
    "    else:\n",
    "        #print(\"non-numeric\")\n",
    "        # best_guess = process.extractOne(x, choices=choices, scorer=scorer)\n",
    "        ## use the first return if you want to see similarity score, otherwise, use the second\n",
    "        return process.extractOne(x, choices=choices, scorer=scorer)        \n",
    "        #return process.extractOne(x, choices=choices, scorer=scorer)[0]\n",
    "\n",
    "# create a second truncated df to trial\n",
    "locations_tsv_trunc_2 = locations_tsv_trunc\n",
    "    \n",
    "# Following post explains why token_sort_ratio might be best \n",
    "## https://medium.com/analytics-vidhya/matching-messy-pandas-columns-with-fuzzywuzzy-4adda6c7994f\n",
    "## tldr: converts each word to a token, then sorts aphabetically. \n",
    "## Streetnames that are abbrievated and in full both start with the same letter so this avoids errors like bway -> w  \n",
    "locations_tsv_trunc_2[\"token_matched\"] = locations_tsv_trunc_2[\"token_re\"].apply(\n",
    "    fuzzy_match,\n",
    "    args=(\n",
    "        master_street_names,\n",
    "        fuzz.token_sort_ratio\n",
    "    )\n",
    ")\n",
    "\n",
    "#end = timer()\n",
    "#print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory_uuid</th>\n",
       "      <th>page_uuid</th>\n",
       "      <th>entry_uuid</th>\n",
       "      <th>location_count</th>\n",
       "      <th>offset_count</th>\n",
       "      <th>token</th>\n",
       "      <th>token_re</th>\n",
       "      <th>token_matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231009</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>400.56767356.497fc4f0-5361-0134-c8c4-00505686a51c</td>\n",
       "      <td>f391c8ec499e11ea8ccce0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>av.</td>\n",
       "      <td>av</td>\n",
       "      <td>(Av, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356654</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>651.56767607.7f6097a0-5361-0134-beb4-00505686a51c</td>\n",
       "      <td>ccec672c49a011eaa112e0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Av.</td>\n",
       "      <td>av</td>\n",
       "      <td>(Av, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102313</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>36.56766992.28a347b0-5361-0134-43e2-00505686a51c</td>\n",
       "      <td>9ee3fea648e411eaae85e0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wall</td>\n",
       "      <td>wall</td>\n",
       "      <td>(Wall, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291231</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>519.56767475.738c4430-5361-0134-275a-00505686a51c</td>\n",
       "      <td>d04f0466499f11ea830de0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>av.</td>\n",
       "      <td>av</td>\n",
       "      <td>(Av, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348728</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>635.56767591.7dd94bf0-5361-0134-493b-00505686a51c</td>\n",
       "      <td>adf9131a49a011eaacece0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EB.</td>\n",
       "      <td>eb</td>\n",
       "      <td>(E, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213842</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>366.56767322.466394b0-5361-0134-2932-00505686a51c</td>\n",
       "      <td>b694da7e499e11ea987ce0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fifth</td>\n",
       "      <td>fifth</td>\n",
       "      <td>(Fifth, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124911</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>80.56767036.2c80f450-5361-0134-74cd-00505686a51c</td>\n",
       "      <td>417f5bb448e611ea84c5e0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457927</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>848.56767804.91966ba0-5361-0134-6545-00505686a51c</td>\n",
       "      <td>4b04600a49a211ea8042e0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Waverley</td>\n",
       "      <td>waverley</td>\n",
       "      <td>(Waverley, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338350</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>614.56767570.7c0f3100-5361-0134-a006-00505686a51c</td>\n",
       "      <td>8646a51c49a011ea973ee0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sixth</td>\n",
       "      <td>sixth</td>\n",
       "      <td>(Sixth, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115407</th>\n",
       "      <td>4b119360-317a-0134-9131-00505686a51c</td>\n",
       "      <td>61.56767017.2abe5ac0-5361-0134-5f2f-00505686a51c</td>\n",
       "      <td>7ee4d91248e511ea97dee0accb5fbfb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Throgg's</td>\n",
       "      <td>throggs</td>\n",
       "      <td>(Thomas, 62)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              directory_uuid  \\\n",
       "231009  4b119360-317a-0134-9131-00505686a51c   \n",
       "356654  4b119360-317a-0134-9131-00505686a51c   \n",
       "102313  4b119360-317a-0134-9131-00505686a51c   \n",
       "291231  4b119360-317a-0134-9131-00505686a51c   \n",
       "348728  4b119360-317a-0134-9131-00505686a51c   \n",
       "...                                      ...   \n",
       "213842  4b119360-317a-0134-9131-00505686a51c   \n",
       "124911  4b119360-317a-0134-9131-00505686a51c   \n",
       "457927  4b119360-317a-0134-9131-00505686a51c   \n",
       "338350  4b119360-317a-0134-9131-00505686a51c   \n",
       "115407  4b119360-317a-0134-9131-00505686a51c   \n",
       "\n",
       "                                                page_uuid  \\\n",
       "231009  400.56767356.497fc4f0-5361-0134-c8c4-00505686a51c   \n",
       "356654  651.56767607.7f6097a0-5361-0134-beb4-00505686a51c   \n",
       "102313   36.56766992.28a347b0-5361-0134-43e2-00505686a51c   \n",
       "291231  519.56767475.738c4430-5361-0134-275a-00505686a51c   \n",
       "348728  635.56767591.7dd94bf0-5361-0134-493b-00505686a51c   \n",
       "...                                                   ...   \n",
       "213842  366.56767322.466394b0-5361-0134-2932-00505686a51c   \n",
       "124911   80.56767036.2c80f450-5361-0134-74cd-00505686a51c   \n",
       "457927  848.56767804.91966ba0-5361-0134-6545-00505686a51c   \n",
       "338350  614.56767570.7c0f3100-5361-0134-a006-00505686a51c   \n",
       "115407   61.56767017.2abe5ac0-5361-0134-5f2f-00505686a51c   \n",
       "\n",
       "                              entry_uuid  location_count  offset_count  \\\n",
       "231009  f391c8ec499e11ea8ccce0accb5fbfb2               0             0   \n",
       "356654  ccec672c49a011eaa112e0accb5fbfb2               0             0   \n",
       "102313  9ee3fea648e411eaae85e0accb5fbfb2               0             0   \n",
       "291231  d04f0466499f11ea830de0accb5fbfb2               0             0   \n",
       "348728  adf9131a49a011eaacece0accb5fbfb2               0             0   \n",
       "...                                  ...             ...           ...   \n",
       "213842  b694da7e499e11ea987ce0accb5fbfb2               0             0   \n",
       "124911  417f5bb448e611ea84c5e0accb5fbfb2               0             0   \n",
       "457927  4b04600a49a211ea8042e0accb5fbfb2               0             0   \n",
       "338350  8646a51c49a011ea973ee0accb5fbfb2               0             0   \n",
       "115407  7ee4d91248e511ea97dee0accb5fbfb2               0             0   \n",
       "\n",
       "           token  token_re    token_matched  \n",
       "231009       av.        av        (Av, 100)  \n",
       "356654       Av.        av        (Av, 100)  \n",
       "102313      Wall      wall      (Wall, 100)  \n",
       "291231       av.        av        (Av, 100)  \n",
       "348728       EB.        eb          (E, 67)  \n",
       "...          ...       ...              ...  \n",
       "213842     Fifth     fifth     (Fifth, 100)  \n",
       "124911        96        96               96  \n",
       "457927  Waverley  waverley  (Waverley, 100)  \n",
       "338350     Sixth     sixth     (Sixth, 100)  \n",
       "115407  Throgg's   throggs     (Thomas, 62)  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tsv_trunc_2\n",
    "\n",
    "# Issues and errors examples:\n",
    "## False negatives: bway -> broadway, 67% similar \n",
    "## False positives: 127th -> 12th, 89% similar\n",
    "## True positives: grand -> Grand, 100% similar\n",
    "## True negatives: 68d -> dry, 33% similar | pl -> Pell, 67% similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(occupations_tsv.entry_uuid.nunique())\n",
    "occupations_tsv.head(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects_tsv.entry_uuid.nunique())\n",
    "subjects_tsv.head(n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discarded | Obsolete Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link](https://stackoverflow.com/questions/40712178/reading-the-json-file-with-multiple-objects-in-python) to help with decoding this particular JSON object. Multiple JSON object within one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens the file and saves it to a pandas df\n",
    "##with open(path + test_json) as f:\n",
    "##    df = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look into the JSON table to check\n",
    "##df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual uniqueness check\n",
    "##line_number = np.array(df.original_hocr_line_number)\n",
    "##unique_elements, counts_elements = np.unique(line_number, return_counts=True)\n",
    "##print(\"Frequency of unique values of the said array:\")\n",
    "##print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels \"a\", \"h\", and \"r\" represent the relative addresses, and address types such as houses, and rear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick glimpse of how the last column might actually look like\n",
    "## df.iloc[124,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.iloc[110,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.iloc[10,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.iloc[4,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.iloc[147, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_labeled_entry = df.labeled_entry.apply(pd.Series)\n",
    "##df_locations = df_labeled_entry[\"locations\"]\n",
    "##df_locations = pd.concat([df_locations, df.original_hocr_line_number], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_locations.iloc[147,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##type(df_locations.iloc[147,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##type(df_locations.iloc[147,0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_locations.iloc[147][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, each labeled entry's location is stored as a list of _n_ dictionaries with two key-value pairs of `value` and `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_locations.iloc[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##type(df_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This checks for existence of labels, duly records the (non)existence, strips it out, appends to another list\n",
    "# This is done w/o loss to order\n",
    "\n",
    "#line_num_list = []\n",
    "#complete_street_name = []\n",
    "#split_street_name = []\n",
    "#labels = []\n",
    "#for entry in range(0,len(df_locations)):\n",
    "#    #print(df_locations.iloc[entry])\n",
    "#    for dicts in df_locations.iloc[entry][0]:\n",
    "#        if 'labels' in dicts:\n",
    "#            for key, value in dicts.items():\n",
    "#                #line_num_list.append(df_locations.iloc[entry][1])\n",
    "#                if key == 'labels':\n",
    "#                    labels.append(value)\n",
    "#                else:\n",
    "#                    complete_street_name.append(value)\n",
    "#                    street_name_split = str(value).split()\n",
    "#                    split_street_name.append(street_name_split)\n",
    "#                    line_num_list.append(df_locations.iloc[entry][1])\n",
    "#        else:\n",
    "#            for key, value in dicts.items():\n",
    "#                line_num_list.append(df_locations.iloc[entry][1])\n",
    "#                labels.append(\" \")\n",
    "#                complete_street_name.append(value)\n",
    "#                street_name_split = str(value).split()\n",
    "#                split_street_name.append(street_name_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that avenues are spelled out and streets are enumerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_street_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlisted_location = pd.concat([pd.Series(complete_street_name), pd.Series(split_street_name), pd.Series(labels), pd.Series(line_num_list)], axis = 1)\n",
    "#unlisted_location.columns = [\"complete_street_name\", \"split_street_name\", \"labels\", \"line_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(line_num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlisted_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first order of business is to test if string is a street number\n",
    "# if it is not, then it is probably a street name, and a comparison can be made\n",
    "# Perform regex to remove the periods\n",
    "# https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "# https://datascience.stackexchange.com/questions/29775/how-to-check-and-correct-misspelling-in-the-data-of-pairs-of-words\n",
    "# http://blog.keyrus.co.uk/fuzzy_matching_101_part_i.html\n",
    "# http://blog.keyrus.co.uk/fuzzy_matching_101_part_ii.html\n",
    "\n",
    "#for i in range(0, len(unlisted_location)):\n",
    "#    non_numeric_street_name = []\n",
    "#    for address_component in unlisted_location.iloc[i, 1]:\n",
    "#        if address_component.isnumeric() == False:\n",
    "#            non_numeric_street_name.append(address_component)\n",
    "#            print(non_numeric_street_name)\n",
    "#        unlisted_location.iloc[i][\"non_numeric\"] = non_numeric_street_name\n",
    "            \n",
    "#        #print(address_component.isnumeric())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlisted_location"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
