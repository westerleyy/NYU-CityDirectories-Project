{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous team used PIL and PyTesseract to parse through the images. I decided to use PIL and PyTesseract instead of Image Magick as it seems more straightforward than using ImageMagick whose API has not been updated for a while, it seems. I am also trying out OpenCV as it has more functionalities and customization options where image preprocessing is concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract 5: 5.0.0-alpha.20191030\n",
      "OpenCV: 4.1.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from io import StringIO    \n",
    "from skimage import io\n",
    "from skimage import transform as tf\n",
    "from skimage.feature import canny\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Set Tesseract path \n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Check tesseract version\n",
    "## Tesseract 5 was used because it is faster and better than tesseract 4\n",
    "print(\"Tesseract 5: \" + str(pytesseract.get_tesseract_version()))\n",
    "\n",
    "#Check cv2 version \n",
    "print(\"OpenCV: \" + str(cv2.__version__))\n",
    "\n",
    "# Test image path \n",
    "test_directory_path = \"./test_directory_files\"\n",
    "folder_name = \"/1847.33f67330-5daf-0134-9838-00505686a51c\"\n",
    "file_name = \"/183.57504747.d4315750-2b8e-0136-1360-47c4533390a8.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered the concept of Histogram Equalization (https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html). However, the results were pretty disastrous. Enhancing the contrast through histogram equalization affected Tesseract's ability to parse through the image and recognize the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file saved\n"
     ]
    }
   ],
   "source": [
    "# cv2 method as suggested by: \n",
    "# https://www.freecodecamp.org/news/getting-started-with-tesseract-part-ii-f7f9a0899b3f/\n",
    "\n",
    "# Reading in image\n",
    "img = cv2.imread(test_directory_path + folder_name + file_name)\n",
    "\n",
    "# Rescale the image    \n",
    "img = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
    "# Convert to gray    \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
    "# Apply dilation and erosion to remove some noise    \n",
    "kernel = np.ones((1, 1), np.uint8)    \n",
    "img = cv2.dilate(img, kernel, iterations=1)    \n",
    "img = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "# Run tesseract\n",
    "result_opencv_string = pytesseract.image_to_string(img)\n",
    "## Get bounding box estimates, lines, confidences, and page numbers\n",
    "## Useful statistics to have but too annoying to print\n",
    "####print(pytesseract.image_to_boxes(img))\n",
    "####print(pytesseract.image_to_data(pic))\n",
    "## Save to file\n",
    "directory = os.path.join(test_directory_path + folder_name)\n",
    "with open(directory + file_name[:-5] + \"_opencv2\" + \".txt\", \"w\") as f: \n",
    "    f.write(result_opencv_string)\n",
    "    print(\"Text file saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"The following chunk was the code used to attempt histogram equalization to improve contrast of the image.\n",
    "     Histogram equalization was applied after the standard grayscale, dilation, erosion, and scaling transformations.\n",
    "     However, it is not very useful in the improving text recognition. In fact, the results were worse.\"\"\"\n",
    "\n",
    "# #Look at the histogram\n",
    "# hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "# cdf = hist.cumsum()\n",
    "# cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
    "# plt.plot(cdf_normalized, color = 'b')\n",
    "# plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "# plt.xlim([0,256])\n",
    "# plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "# plt.show()\n",
    "\n",
    "# #Run equalization\n",
    "# equ = cv2.equalizeHist(img)\n",
    "# res = np.hstack((img,equ)) #stacking images side-by-side\n",
    "# plt.imshow(res, cmap = 'gray'), plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# #Histogram for equalized\n",
    "# hist1, bins1 = np.histogram(equ.flatten(),256,[0,256])\n",
    "# cdf1 = hist1.cumsum()\n",
    "# cdf1_normalized = cdf1 * float(hist1.max()) / cdf1.max()\n",
    "# plt.plot(cdf1_normalized, color = 'b')\n",
    "# plt.hist(equ.flatten(),256,[0,256], color = 'r')\n",
    "# plt.xlim([0,256])\n",
    "# plt.legend(('cdf1','histogram'), loc = 'upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Run tesseract\n",
    "# result_opencv_string = pytesseract.image_to_string(equ)\n",
    "# # Save to file\n",
    "# directory = os.path.join(test_directory_path + folder_name)\n",
    "# with open(directory + file_name[:-5] + \"_opencv2\" + \"equ\" + \".txt\", \"w\") as f: \n",
    "#     f.write(result_opencv_string)\n",
    "#     print(\"Text file saved\")\n",
    "\n",
    "# #What about CLAHE\n",
    "# # create a CLAHE object\n",
    "\n",
    "# clahe = cv2.createCLAHE()\n",
    "# cl1 = clahe.apply(img)\n",
    "# res2 = np.hstack((img,cl1)) #stacking images side-by-side\n",
    "# plt.imshow(res2, cmap = 'gray'), plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# #Histogram for localized contrast change\n",
    "# hist2, bins2 = np.histogram(cl1.flatten(),256,[0,256])\n",
    "# cdf2 = hist2.cumsum()\n",
    "# cdf2_normalized = cdf2 * float(hist2.max()) / cdf2.max()\n",
    "# plt.plot(cdf2_normalized, color = 'b')\n",
    "# plt.hist(cl1.flatten(),256,[0,256], color = 'r')\n",
    "# plt.xlim([0,256])\n",
    "# plt.legend(('cdf2','histogram'), loc = 'upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Run tesseract\n",
    "# result_opencv_string = pytesseract.image_to_string(cl1)\n",
    "\n",
    "# # Save to file\n",
    "# directory = os.path.join(test_directory_path + folder_name)\n",
    "# with open(directory + file_name[:-5] + \"_opencv2\" + \"cl1\" + \".txt\", \"w\") as f: \n",
    "#     f.write(result_opencv_string)\n",
    "#     print(\"Text file saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the preprocessing done by CUSP sans bounding box detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function from previous CUSP team \n",
    "# Added in the pivot to return an hOCR object instead\n",
    "\n",
    "def preprocessImage(test_directory_path):\n",
    "        \"\"\"Processes each column image to make it black and white and then using PyTesseract to return results\"\"\"\n",
    "\n",
    "        image = Image.open(test_directory_path + folder_name + file_name)\n",
    "        thresh = 150\n",
    "        fn = lambda x : 255 if x > thresh else 0\n",
    "\n",
    "        # Uses PIL's Image to convert to greyscale\n",
    "        bw_image = image.convert('L').point(fn, mode='1')\n",
    "        print(type(bw_image))\n",
    "        enhanceImage = ImageEnhance.Sharpness(bw_image)\n",
    "        contrast = ImageEnhance.Contrast(enhanceImage.image)\n",
    "        brightness = ImageEnhance.Brightness(contrast.image)\n",
    "        enhancedImage = brightness.image\n",
    "        \n",
    "      \n",
    "        # Recognize text with tesseract for python    \n",
    "        result = pytesseract.image_to_pdf_or_hocr(enhancedImage, lang=\"eng\", extension = \"hocr\")\n",
    "        result_string = pytesseract.image_to_string(enhancedImage)\n",
    "\n",
    "        \n",
    "        # save hOCR to file\n",
    "        ## wb NOT w for hOCR\n",
    "        directory = os.path.join(test_directory_path + folder_name)\n",
    "        with open(directory + file_name[:-5] + \".hocr\", \"wb\") as f: \n",
    "            f.write(result)\n",
    "            print(\"hOCR saved\")\n",
    "        with open(directory + file_name[:-5] + \"_bw_\" + \".txt\", \"w\") as f: \n",
    "            f.write(result_opencv_string)\n",
    "        return print(\"Text file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This method will not work because PIL cannot work with an np array that is returned by cv2\"\"\"\n",
    "def preprocessImage_cv2(test_directory_path, folder_name, file_name):\n",
    "        \"\"\"Processes each column image to make it black and white and then using PyTesseract to return results\"\"\"\n",
    "        # this path set-up is not ideal but it can be tweaked easily later\n",
    "        image = cv2.imread(test_directory_path + folder_name + file_name)\n",
    "        # Rescale the image    \n",
    "        image = cv2.resize(image, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
    "        # Convert to gray    \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)    \n",
    "        # Apply dilation and erosion to remove some noise    \n",
    "        kernel = np.ones((1, 1), np.uint8)    \n",
    "        image = cv2.dilate(image, kernel, iterations=1)    \n",
    "        image = cv2.erode(image, kernel, iterations=1)\n",
    "        \n",
    "        print(type(image))\n",
    "        \n",
    "        # Using PIL to further enhance image\n",
    "        enhanceImage = Ima geEnhance.Sharpness(image)\n",
    "        contrast = ImageEnhance.Contrast(enhanceImage.image)\n",
    "        brightness = ImageEnhance.Brightness(contrast.image)\n",
    "        enhancedImage = brightness.image\n",
    "        \n",
    "        # Recognize text with tesseract for python\n",
    "        # first returns hocr\n",
    "        # second returns string\n",
    "        result_opencv_hocr = pytesseract.image_to_pdf_or_hocr(enhancedImage, lang=\"eng\", extension = \"hocr\")\n",
    "        result_opencv_string = pytesseract.image_to_string(enhancedImage)\n",
    "        \n",
    "        # Batch processing with a single file containing the list of multiple image file paths\n",
    "        ###print(pytesseract.image_to_string('images.txt'))\n",
    "        \n",
    "        # Get bounding box estimates, lines, confidences, and page numbers\n",
    "        print(pytesseract.image_to_data(image))\n",
    "        \n",
    "        # save hOCR to file\n",
    "        ## wb NOT w for hOCR\n",
    "        directory = os.path.join(test_directory_path + folder_name)\n",
    "        with open(directory + file_name[:-5] + \"_opencv2\" + \".hocr\", \"wb\") as f: \n",
    "            f.write(result_opencv_hocr)\n",
    "            print(\"hOCR saved\")\n",
    "        with open(directory + file_name[:-5] + \"_opencv2\" + \".txt\", \"w\") as f: \n",
    "            f.write(result_opencv_string)\n",
    "        return print(\"Text file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "hOCR saved\n",
      "Text file saved\n"
     ]
    }
   ],
   "source": [
    "preprocessImage(test_directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have gone ahead and done a comparison between the CUSP's method with PIL and OpenCV 4.1.1. There is no real difference between the two beyond the occassional character and formatting difference. A more substantial test will require running the hOCR column detection script to see which approach's hOCR output is more likely to yield accurate results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
